{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f04f76f",
   "metadata": {},
   "source": [
    "# Motivational Qualities of Songs for Daily Activities\n",
    "\n",
    "In this assignment you will work on a study on song features and how they can be used as the basis for recommendations for specific daily activities. The study is:\n",
    "\n",
    "* Kim, Y., Aiello, L.M. & Quercia, D. PepMusic: motivational qualities of songs for daily activities. EPJ Data Sci. 9, 13 (2020). https://doi.org/10.1140/epjds/s13688-020-0221-9\n",
    "\n",
    "You can download the study from the above link. You can use the dataset provided by the authors, which is available inside the present folder at [data_archive_20190201.json](./data_archive_20190201.json).\n",
    "\n",
    "---\n",
    "\n",
    "> Panos Louridas, Associate Professor <br />\n",
    "> Department of Management Science and Technology <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> louridas@aueb.gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d16b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8453c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pd.read_json('./data_archive_20190201.json').transpose()\n",
    "json_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract every information from features into separate columns\n",
    "features_df = pd.json_normalize(json_data['features'])\n",
    "\n",
    "# Keep important infromation in separate dataframe\n",
    "df = pd.concat([json_data[['trackId', 'artists', 'songTitle']], features_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4468779",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccbea3",
   "metadata": {},
   "source": [
    "### Q1: Clustering \n",
    "\n",
    "You will perform a clustering on the songs, using KMeans. The authors identify the optimum number of clusters by using the elbow method (gives four clusters) and the silhouette score (gives two) clusters and taking their average, i.e., three clusters.\n",
    "\n",
    "Use both methods, like the authors, check the results, and then use three clusters. Visualize the clusters by using PCA on two dimensions.\n",
    "\n",
    "Note that the data given by the authors contain the results of their clustering. Of course this will not be a feature that you will use for your clustering. The features you will use for clustering will be:\n",
    "\n",
    "* `chordsScale`\n",
    "\n",
    "* `chordsKey`\n",
    "\n",
    "* `bpm`\n",
    "\n",
    "* `rhythmHist`\n",
    "\n",
    "* `regularity`\n",
    "\n",
    "* `rhythmPattern`\n",
    "\n",
    "* `keyKey`\n",
    "\n",
    "* `loudness`\n",
    "\n",
    "* `pitchBiHist`\n",
    "\n",
    "* `keyScale`\n",
    "\n",
    "Not all of these features are atomic, and not all of these features are numerical, so you should make the necessary transformations in the data so that you get all features in a single two-dimensional matrix.\n",
    "\n",
    "Once you finish your clustering, compare the clusters that you have found with the clusters that the authors have found; how similar are your clusters to theirs? The authors assign activities, given by `activityType`, to clusters as in Table 2. Interpret your clusters like the authors do in the text of the paper and in figures 5, 6, as best as you can. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a16bb1",
   "metadata": {},
   "source": [
    "We can see that some columns have categorical values. We will need to get the data in the correct format, since clustering algorithms like KMeans expect a flat, numerical matrix where each feature corresponds to a single numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54953129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that gets the categorical columns and returns a dataframe with a each columns expaned into multiple ones\n",
    "def encode_categorical_values(df, columns_list):\n",
    "  encoder = OneHotEncoder()\n",
    "  categorical_encoded = encoder.fit_transform(df[columns_list]).toarray()\n",
    "  df = pd.DataFrame(categorical_encoded, columns=encoder.get_feature_names_out(columns_list))\n",
    "  return df\n",
    "\n",
    "# Use the method for our categorical data\n",
    "categorical_columns = ['chordsScale', 'chordsKey', 'keyKey', 'keyScale']\n",
    "categorical_df = encode_categorical_values(df, categorical_columns)\n",
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand columns that hold list values, into multiple columns\n",
    "def expand_list_columns(df, columns_list):\n",
    "  expanded_df = []\n",
    "  for column in columns_list:\n",
    "    expanded = pd.DataFrame(\n",
    "      df[column].tolist(),\n",
    "      columns=[f\"{column}_{i+1}\" for i in range(len(df[column].iloc[0]))]\n",
    "    )\n",
    "    expanded_df.append(expanded)\n",
    "\n",
    "  expanded_df = pd.concat(expanded_df, axis=1)\n",
    "  return expanded_df\n",
    "\n",
    "list_columns = ['rhythmHist', 'rhythmPattern']\n",
    "lists_df = expand_list_columns(df, list_columns)\n",
    "lists_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0b8b6",
   "metadata": {},
   "source": [
    "The `pitchBiHist` is different because it contains **nested lists**, while other columns like `rhythmHist` have flat lists. Instead of expanding it into many columns (which will increase complexity by a lot), we calculate summary statistics like **mean, standard deviation** to capture its overall behavior in a simpler way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate List Features\n",
    "dpitchBiHist_mean_df = df['pitchBiHist'].apply(lambda x: np.mean(x[0]))\n",
    "dpitchBiHist_std_df = df['pitchBiHist'].apply(lambda x: np.std(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['bpm', 'regularity', 'loudness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108eed7",
   "metadata": {},
   "source": [
    "We will now combine all columns into a **flat, numerical matrix** where each feature corresponds to a single numeric value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.concat([\n",
    "    df[numerical_columns], \n",
    "    categorical_df, \n",
    "    lists_df,\n",
    "    dpitchBiHist_mean_df,\n",
    "    dpitchBiHist_std_df\n",
    "  ], axis=1)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6e709",
   "metadata": {},
   "source": [
    "We can see that the variances vary a lot, so we need to scale the data using **Standard Scaler** for optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(processed_df)\n",
    "\n",
    "scaled_df = pd.DataFrame(\n",
    "  scaled_df,\n",
    "  index=processed_df.index,\n",
    "  columns=processed_df.columns\n",
    ")\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf18f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f1cf9",
   "metadata": {},
   "source": [
    "The variances are pretty similar with each other. This means that we can proceed with finding the optimal number of clusters in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73f8df",
   "metadata": {},
   "source": [
    "We apply the **Elbow Method** in order to find the optimal amount of clusters to use in our KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e818ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(random_state=0)\n",
    "visualizer = KElbowVisualizer(kmeans, k=(1,11))\n",
    "\n",
    "visualizer.fit(scaled_df)\n",
    "_ = visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99b134",
   "metadata": {},
   "source": [
    "We can see from the elbow method's results that one may choose 3 or 4 as k.\n",
    "We also apply the **Silhouette Score method** to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2 * 5,  10 * 4))\n",
    "\n",
    "scores = {}\n",
    "for n_clusters in range(2, 11):\n",
    "    plt.subplot(10, 2, n_clusters - 1)\n",
    "    kmeans = KMeans(n_clusters, random_state=42)\n",
    "    visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')\n",
    "    visualizer.fit(scaled_df)\n",
    "    scores[n_clusters] = visualizer.silhouette_score_\n",
    "    plt.title(f'clusters: {n_clusters} score: {visualizer.silhouette_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3209e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the amount of clusters sorted by the overall score\n",
    "sorted(scores.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e10f9",
   "metadata": {},
   "source": [
    "We can see from the results of the Silhouette Score method that one may choose 2 as k.\n",
    "\n",
    "We will take the **mean of the observations**, and fit our KMeans model with **number of clusters = 3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "clusters = kmeans.fit_predict(scaled_df)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7c0f2",
   "metadata": {},
   "source": [
    "We will now map each song to its cluster and add the result as new column in the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary\n",
    "cluster_names = {0: 'intense', 1: 'calm', 2: 'vibrant'}\n",
    "\n",
    "df['clusteringLabel'] = [cluster_names[cluster] for cluster in clusters]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(kmeans.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9136c0a",
   "metadata": {},
   "source": [
    "We can observe that the clusters are well splitted:\n",
    "* 344 songs where inserted on the **Intense** cluster.\n",
    "* 257 songs where inserted on the **Calm** cluster.\n",
    "* 506 songs where inserted on the **Vibrant** cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eaec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_df)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f122c06",
   "metadata": {},
   "source": [
    "* The explained variance ratios for the two principal components are **0.3721** and **0.0392**, respectively.\n",
    "* The first principal component captures approximately **37.2%** of the total variance in the data, indicating it is the most significant contributor to dimensionality reduction.\n",
    "* The second principal component accounts for **3.9%** of the variance, suggesting diminishing returns in additional dimensions.\n",
    "* Together, these two components explain **41.1%** of the dataset’s variance, implying that further components may be necessary for more comprehensive representation. While more components might better represent the dataset, these two are adequate for visual exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "mapped_labels = [cluster_names[label] for label in kmeans.labels_]\n",
    "\n",
    "_ = sns.scatterplot(\n",
    "  x=pca_data[:, 0], \n",
    "  y=pca_data[:, 1], \n",
    "  hue=mapped_labels, \n",
    "  palette=sns.color_palette('muted', n_colors=3)\n",
    "  )\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbfcdf",
   "metadata": {},
   "source": [
    "From the scatterplot, we can observe that the data points are effectively clustered, showing clear separation between different groups. The distribution of points within each cluster appears dense and well-defined, suggesting that the clustering method (e.g., KMeans) has performed well. The PCA transformation helped reduce dimensionality while maintaining significant structure in the data, providing a simplified yet informative view of the underlying patterns. The separation between clusters highlights the distinctiveness of the groups, which can be useful for further analysis or classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot a boxplot showing the bpm for each cluster label\n",
    "sns.boxplot(\n",
    "  x='clusteringLabel', \n",
    "  y='bpm', \n",
    "  data=df, \n",
    "  ax=axes[0],\n",
    "  boxprops=dict(facecolor='none', edgecolor='black')\n",
    "  )\n",
    "\n",
    "# Plot a boxplot showing the loudness for each cluster label\n",
    "sns.boxplot(\n",
    "  x='clusteringLabel', \n",
    "  y='loudness', \n",
    "  data=df, \n",
    "  ax=axes[1],\n",
    "  boxprops=dict(facecolor='none', edgecolor='black')\n",
    "  )\n",
    "\n",
    "# Plot a boxplot showing the danceability for each cluster label\n",
    "sns.boxplot(\n",
    "  x='clusteringLabel', \n",
    "  y='regularity', \n",
    "  data=df, \n",
    "  ax=axes[2],\n",
    "  boxprops=dict(facecolor='none', edgecolor='black')\n",
    "  )\n",
    "\n",
    "axes[0].set_ylabel('BPM')\n",
    "axes[1].set_ylabel('Loudness')\n",
    "axes[2].set_ylabel('Danceability')\n",
    "\n",
    "# Remove x-axis labels and grid lines in each subplot\n",
    "[axe.set_xlabel('') for axe in axes]\n",
    "[axe.grid(False) for axe in axes]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf113f",
   "metadata": {},
   "source": [
    "The analysis of tempo, loudness, and danceability reveals notable differences across the three music archetypes—calm, vibrant, and intense. \n",
    "* For both loudness and danceability, the intense group exhibits the highest values, while the calm group has the lowest. The vibrant group falls in between. \n",
    "* In contrast, the tempo, measured in beats per minute, is highest for the calm group, followed by vibrant and intense. This is likely because the calm group, consisting of instrumental genres like classical and meditation music, tends to feature slower, more complex rhythms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33972671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_factory(keys, values, axes=None, color='b', fontsize=10, figsize=(5, 5)):\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    if axes is None:\n",
    "        # Initialise the spider plot.\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "    else:\n",
    "        ax = axes\n",
    "        \n",
    "    num_categories = len(keys)\n",
    " \n",
    "    # What will be the angle of each axis in the plot? \n",
    "    # We divide the plot / number of variables + 1.\n",
    "    # We add one because we want to do a complete circle.\n",
    "    angles = np.arange(num_categories + 1)\n",
    "    angles = angles / num_categories * 2 * np.pi \n",
    "    angles[-1] = angles[0]\n",
    " \n",
    "    # We want the first axis to be on top.\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    # Theta direction is -1 clockwise,\n",
    "    # and 1 counterclockwise\n",
    "    ax.set_theta_direction(-1)\n",
    " \n",
    "    # Draw one axis per variable and add x labels\n",
    "    ax.tick_params(labelsize=fontsize)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(keys)\n",
    " \n",
    "    # Draw y labels\n",
    "    ax.set_rlabel_position(0)\n",
    "\n",
    "    values.append(values[0])\n",
    "    ax.plot(list(angles), values, \n",
    "            linewidth=1, linestyle='solid', color=color)\n",
    "\n",
    "    ax.fill(angles, values, alpha=0.2, color=color)\n",
    "    yticks = ax.get_yticks()\n",
    "    ax.set_yticklabels([])\n",
    "    ylims = ax.get_ylim()\n",
    "    ax.set_ylim(min(yticks[0], ylims[0]), \n",
    "                max(yticks[-1], ylims[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce545d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"C major\", \"F major\", \"G major\", \"A minor\", \"A# major\", \"A major\", \"E major\"]\n",
    "colors = ['b', 'r', 'g']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Iterate over each clustering label and plot the radar chart\n",
    "for label, color in zip(df['clusteringLabel'].unique(), colors):\n",
    "    cluster_data = scaled_df[df['clusteringLabel'] == label]\n",
    "    values = [cluster_data['chordsKey_C'].mean(), \n",
    "              cluster_data['chordsKey_F'].mean(),\n",
    "              cluster_data['chordsKey_G'].mean(),\n",
    "              cluster_data['chordsKey_A'].mean(),\n",
    "              cluster_data['chordsKey_A#'].mean(),\n",
    "              cluster_data['chordsKey_E'].mean(),\n",
    "              cluster_data['keyScale_major'].mean()]\n",
    "    \n",
    "    radar_factory(labels, values, axes=ax, color=color)\n",
    "\n",
    "# Disable circular grid lines\n",
    "ax.yaxis.grid(False)\n",
    "\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], color=colors[0], lw=2, label='Calm'),\n",
    "    Line2D([0], [0], color=colors[1], lw=2, label='Vibrant'),\n",
    "    Line2D([0], [0], color=colors[2], lw=2, label='Intense')\n",
    "]\n",
    "\n",
    "plt.legend(\n",
    "    handles=custom_legend, \n",
    "    bbox_to_anchor=(1.1, 1.1),\n",
    "    frameon=True, \n",
    "    edgecolor='black'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6db166",
   "metadata": {},
   "source": [
    "For the three music archetypes, the top musical keys for each group are as follows:\n",
    "\n",
    "- **Calm Group:** The most common keys are A Major, A# Major, and A minor.\n",
    "- **Intense Group:** The leading keys are E Major, G Major, and A# Major.\n",
    "- **Vibrant Group:** The most frequent keys are A minor, E Major, and F Major.\n",
    "\n",
    "These key choices reflect the distinct musical preferences and overall mood characteristics within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (json_data['clusteringLabel'] == df['clusteringLabel']).sum()\n",
    "y = len(json_data)\n",
    "\n",
    "print(f'{x} found with the right label from {y}. Percentage is {x/y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cae0c0",
   "metadata": {},
   "source": [
    "This percentage indicates that the clustering performed with KMeans on the dataset has a moderate match with the ground truth labels, but it is far from perfect. The difference between my results and the aticle's clusters may stem from variations in feature selection, scaling methods, or the clustering algorithm used. Their approach may have utilized a more sophisticated method or domain-specific considerations that yielded more accurate clustering results. Therefore, the relatively low percentage suggests that this model could benefit from further refinement and feature adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952a525",
   "metadata": {},
   "source": [
    "### Q2: Classification\n",
    "\n",
    "Following the classification, the authors build a classifier to predict the class (defined as the cluster) of a song. The authors build their classifier using Random Forests and they use a series of models, described in Table 3. Do the same, for all models, using scikit-learn, XGBoost, LightGBM, and CatBoost. Report your results.\n",
    "\n",
    "Beyond the tree-based classifiers, proceed to build a neural-network classifier using TensorFlow or PyTorch. Report also your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1210adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df['clusteringLabel'] = df['clusteringLabel']\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a57218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: REMOVE THIS\n",
    "scaled_df = scaled_df.iloc[:100]\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group columns by their prefix\n",
    "grouped_columns = {\n",
    "  'chordsScale': [col for col in scaled_df.columns if col.startswith('chordsScale')],\n",
    "  'chordsKey': [col for col in scaled_df.columns if col.startswith('chordsKey')],\n",
    "  'keyKey': [col for col in scaled_df.columns if col.startswith('keyKey')],\n",
    "  'keyScale': [col for col in scaled_df.columns if col.startswith('keyScale')],\n",
    "  'rhythmPattern': [col for col in scaled_df.columns if col.startswith('rhythmPattern')],\n",
    "  'rhythmHist': [col for col in scaled_df.columns if col.startswith('rhythmHist')],\n",
    "  'pitchBiHist': [col for col in scaled_df.columns if col.startswith('pitchBiHist')], \n",
    "  'bpm': ['bpm'],\n",
    "  'regularity': ['regularity'],\n",
    "  'loudness': ['loudness']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67671f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'Rhythm Histogram (RH)': (grouped_columns['rhythmHist']),\n",
    "    'Rhythm Patterns (RP)': (grouped_columns['rhythmPattern']),\n",
    "    'Stimulative Loudness': (grouped_columns['loudness']),\n",
    "    'Stimulative Tempo': (grouped_columns['bpm']),\n",
    "    'Danceability': (\n",
    "      grouped_columns['bpm'] +\n",
    "      grouped_columns['regularity'] +\n",
    "      grouped_columns['rhythmHist'] +\n",
    "      grouped_columns['rhythmPattern']),\n",
    "    'Melody': (grouped_columns['pitchBiHist']),\n",
    "    'Harmony': (\n",
    "      grouped_columns['chordsScale'] +\n",
    "      grouped_columns['chordsKey'] +\n",
    "      grouped_columns['keyKey'] +\n",
    "      grouped_columns['keyScale']),\n",
    "    'All except RH and RP': (\n",
    "      grouped_columns['loudness'] +\n",
    "      grouped_columns['bpm'] +\n",
    "      grouped_columns['regularity'] +\n",
    "      grouped_columns['pitchBiHist'] +\n",
    "      grouped_columns['chordsScale'] +\n",
    "      grouped_columns['chordsKey'] +\n",
    "      grouped_columns['keyKey'] +\n",
    "      grouped_columns['keyScale']),\n",
    "    'All': (\n",
    "      grouped_columns['chordsScale'] +\n",
    "      grouped_columns['chordsKey'] +\n",
    "      grouped_columns['keyKey'] +\n",
    "      grouped_columns['keyScale'] +\n",
    "      grouped_columns['rhythmPattern'] +\n",
    "      grouped_columns['rhythmHist'] +\n",
    "      grouped_columns['pitchBiHist'] +\n",
    "      grouped_columns['bpm']) +\n",
    "      grouped_columns['regularity'] +\n",
    "      grouped_columns['loudness']\n",
    "}\n",
    "\n",
    "# method that gets the columns by category\n",
    "get_columns_by_category = {\n",
    "  group: scaled_df[columns + ['clusteringLabel']] for group, columns in categories.items()\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_baseline(df):\n",
    "    X = df.drop('clusteringLabel', axis=1)\n",
    "    y = df['clusteringLabel']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, \n",
    "        y, \n",
    "        test_size=0.3, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Initialize the DummyClassifier with the 'stratified' strategy\n",
    "    baseline_clf = DummyClassifier(strategy='stratified', random_state=42)\n",
    "    baseline_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = baseline_clf.predict(X_test)\n",
    "    \n",
    "    # Get the classification report\n",
    "    class_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "     # Initialize a dictionary to store the metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # Add per-class Accuracy, Precision, Recall, F1-Score for each category\n",
    "    for class_name, metrics_data in class_report_dict.items():\n",
    "        if class_name not in ['accuracy', 'macro avg', 'weighted avg']:  # Skip non-class metrics\n",
    "            class_accuracy = (y_pred == y_test)[y_test == class_name].mean()\n",
    "            metrics[class_name] = {\n",
    "                'accuracy': class_accuracy,\n",
    "                'precision': metrics_data.get('precision', None),\n",
    "                'recall': metrics_data.get('recall', None),\n",
    "                'f1-score': metrics_data.get('f1-score', None)\n",
    "            }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "3ed13f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression(df, model, n_splits=10):\n",
    "    X = df.drop('clusteringLabel', axis=1)\n",
    "    y = df['clusteringLabel']\n",
    "\n",
    "    # Initialize StratifiedKFold with given number of splits\n",
    "    skf = StratifiedKFold(n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    all_metrics = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        clf = OneVsRestClassifier(model)\n",
    "        # Train the classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and get classification report\n",
    "        y_pred = clf.predict(X_test)\n",
    "        class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # Collect fold metrics\n",
    "        fold_metrics = {'accuracy': accuracy_score(y_test, y_pred)}\n",
    "        for class_name, metrics in class_report.items():\n",
    "            if class_name not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                class_accuracy = (y_pred == y_test)[y_test == class_name].mean()\n",
    "                fold_metrics[class_name] = {\n",
    "                    'accuracy': class_accuracy,\n",
    "                    'precision': metrics.get('precision'),\n",
    "                    'recall': metrics.get('recall'),\n",
    "                    'f1-score': metrics.get('f1-score')\n",
    "                }\n",
    "\n",
    "        all_metrics.append(fold_metrics)\n",
    "\n",
    "    # Average metrics across folds\n",
    "    avg_metrics = {}\n",
    "\n",
    "    for fold_metrics in all_metrics:\n",
    "        # Average per-class metrics\n",
    "        for class_name in fold_metrics:\n",
    "            if class_name not in ['accuracy']:\n",
    "                if class_name not in avg_metrics:\n",
    "                    avg_metrics[class_name] = {'accuracy': [], 'precision': [], 'recall': [], 'f1-score': []}\n",
    "\n",
    "                avg_metrics[class_name]['accuracy'].append(fold_metrics[class_name]['accuracy'])\n",
    "                avg_metrics[class_name]['precision'].append(fold_metrics[class_name]['precision'])\n",
    "                avg_metrics[class_name]['recall'].append(fold_metrics[class_name]['recall'])\n",
    "                avg_metrics[class_name]['f1-score'].append(fold_metrics[class_name]['f1-score'])\n",
    "\n",
    "    # Calculate the averages\n",
    "    for class_name, metrics in avg_metrics.items():\n",
    "        avg_metrics[class_name]['accuracy'] = np.mean(metrics['accuracy'])\n",
    "        avg_metrics[class_name]['precision'] = np.mean(metrics['precision'])\n",
    "        avg_metrics[class_name]['recall'] = np.mean(metrics['recall'])\n",
    "        avg_metrics[class_name]['f1-score'] = np.mean(metrics['f1-score'])\n",
    "\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "aba631fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_results_table(model, n_splits=10):\n",
    "    results = []\n",
    "\n",
    "    # Assuming get_columns_by_category is your dictionary with categories and DataFrames\n",
    "    for category, df in get_columns_by_category.items():\n",
    "        category_metrics = perform_regression(df, model, n_splits)\n",
    "\n",
    "        # Iterate over each class in the metrics\n",
    "        for class_name, metrics in category_metrics.items():\n",
    "            if class_name not in ['accuracy', 'macro avg', 'weighted avg']:  # Exclude non-class metrics\n",
    "                row = {\n",
    "                    'Category': category,\n",
    "                    'Class': class_name,\n",
    "                    'Accuracy': metrics.get('accuracy', None),\n",
    "                    'Precision': metrics.get('precision', None),\n",
    "                    'Recall': metrics.get('recall', None),\n",
    "                    'F1-Score': metrics.get('f1-score', None),\n",
    "                }\n",
    "                results.append(row)\n",
    "\n",
    "    # Now, get the baseline results for each class in this category\n",
    "    baseline_metrics = perform_baseline(df)\n",
    "\n",
    "    # Iterate over each class in the baseline metrics\n",
    "    for class_name, metrics in baseline_metrics.items():\n",
    "        if class_name not in ['accuracy', 'macro avg', 'weighted avg']:  # Exclude non-class metrics\n",
    "            row = {\n",
    "                'Category': 'Baseline',\n",
    "                'Class': class_name,\n",
    "                'Accuracy': metrics.get('accuracy', None),\n",
    "                'Precision': metrics.get('precision', None),\n",
    "                'Recall': metrics.get('recall', None),\n",
    "                'F1-Score': metrics.get('f1-score', None),\n",
    "            }\n",
    "            results.append(row)\n",
    "\n",
    "    # Convert the list of rows into a DataFrame and return it\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "ae9efe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/michaeltheophanopoulos/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rhythm Histogram (RH)</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rhythm Histogram (RH)</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rhythm Histogram (RH)</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.888095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rhythm Patterns (RP)</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.958858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rhythm Patterns (RP)</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rhythm Patterns (RP)</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.751429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stimulative Loudness</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.852404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stimulative Loudness</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.446667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stimulative Loudness</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stimulative Tempo</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.682262</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.653231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stimulative Tempo</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.206667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Stimulative Tempo</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Danceability</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.960256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Danceability</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Danceability</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Melody</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.848881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Melody</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Melody</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Harmony</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.606151</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.652711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Harmony</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Harmony</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>All except RH and RP</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.944048</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.932264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>All except RH and RP</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>All except RH and RP</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.609048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>All</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>All</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>All</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.805714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>intense</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>vibrant</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Category    Class  Accuracy  Precision    Recall  F1-Score\n",
       "0   Rhythm Histogram (RH)     calm  0.983333   0.985714  0.983333  0.983217\n",
       "1   Rhythm Histogram (RH)  intense  0.750000   0.750000  0.750000  0.733333\n",
       "2   Rhythm Histogram (RH)  vibrant  0.916667   0.866667  0.916667  0.888095\n",
       "3    Rhythm Patterns (RP)     calm  0.966667   0.954762  0.966667  0.958858\n",
       "4    Rhythm Patterns (RP)  intense  0.550000   0.633333  0.550000  0.560000\n",
       "5    Rhythm Patterns (RP)  vibrant  0.783333   0.750000  0.783333  0.751429\n",
       "6    Stimulative Loudness     calm  0.883333   0.842857  0.883333  0.852404\n",
       "7    Stimulative Loudness  intense  0.450000   0.516667  0.450000  0.446667\n",
       "8    Stimulative Loudness  vibrant  0.566667   0.636667  0.566667  0.528571\n",
       "9       Stimulative Tempo     calm  0.650000   0.682262  0.650000  0.653231\n",
       "10      Stimulative Tempo  intense  0.250000   0.183333  0.250000  0.206667\n",
       "11      Stimulative Tempo  vibrant  0.233333   0.240000  0.233333  0.223333\n",
       "12           Danceability     calm  0.966667   0.954762  0.966667  0.960256\n",
       "13           Danceability  intense  0.650000   0.766667  0.650000  0.680000\n",
       "14           Danceability  vibrant  0.833333   0.775000  0.833333  0.785714\n",
       "15                 Melody     calm  0.866667   0.844286  0.866667  0.848881\n",
       "16                 Melody  intense  0.050000   0.050000  0.050000  0.050000\n",
       "17                 Melody  vibrant  0.400000   0.441667  0.400000  0.403333\n",
       "18                Harmony     calm  0.716667   0.606151  0.716667  0.652711\n",
       "19                Harmony  intense  0.200000   0.175000  0.200000  0.166667\n",
       "20                Harmony  vibrant  0.233333   0.383333  0.233333  0.270000\n",
       "21   All except RH and RP     calm  0.933333   0.944048  0.933333  0.932264\n",
       "22   All except RH and RP  intense  0.550000   0.566667  0.550000  0.546667\n",
       "23   All except RH and RP  vibrant  0.666667   0.575000  0.666667  0.609048\n",
       "24                    All     calm  0.983333   0.983333  0.983333  0.983333\n",
       "25                    All  intense  0.700000   0.733333  0.700000  0.693333\n",
       "26                    All  vibrant  0.816667   0.841667  0.816667  0.805714\n",
       "27               Baseline     calm  0.714286   0.833333  0.714286  0.769231\n",
       "28               Baseline  intense  0.000000   0.000000  0.000000  0.000000\n",
       "29               Baseline  vibrant  0.500000   0.222222  0.500000  0.307692"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, verbose=0)\n",
    "results_table = produce_results_table(model)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=42, verbosity=0)\n",
    "results_table = produce_results_table(model, n_splits=2, oneVsRest = True)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(metric='auc',random_state=42, verbose=-1, n_jobs=1, oneVsRest = False)\n",
    "results_table = produce_results_table(model)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=0, random_state=42, oneVsRest = False)\n",
    "results_table = produce_results_table(model, n_splits=1)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fd231",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "You will submit a Jupyter notebook that will contain all your code, data, and analysis. Ensure that the notebook will run correctly in a computer that is not your own. That means, among other things, that it does not contain absolute paths. Remember that a notebook is not a collection of code cells thrown together; it should contain as much text as necessary for a person to understand what you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce37c4",
   "metadata": {},
   "source": [
    "## Honor Code\n",
    "\n",
    "You understand that this is an individual assignment, and as such you must carry it out alone. You may seek help on the Internet, on ChatGPT/Gemini/etc., by Googling or searching in StackOverflow for general questions pertaining to the use of Python and pandas libraries and idioms. However, it is not right to ask direct questions that relate to the assignment and where people will actually solve your problem by answering them. You may discuss with your colleagues in order to better understand the questions, if they are not clear enough, but you should not ask them to share their answers with you, or to help you by giving specific advice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
